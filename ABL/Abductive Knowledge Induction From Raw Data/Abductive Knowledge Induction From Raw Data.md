# Abductive Knowledge Induction From Raw Data

## Problem

推理模型需要一个完善的知识库，但是实际应用中不现实

## Goal

设计一种推理模型（abduction），将神经网络模型和逻辑归纳统一，能够直接从raw data中提取知识。

## Proposed Approach

### Learning Problem

将问题抽象为如下：

在给定知识库$B$，输入$x$，reasoning model$H$，预测模型$\theta$的情况下，求一组参数$(H^*, \theta^*)$使得在这些条件下得到ground truth $y$和中间隐藏的结果$z$（在文章中是手写数字识别）的概率最大。

就是在给定条件下求一组参数，使得得到正确结果的概率最大。

![img](https://static.cdn.readpaper.com/aiKnowledge/screenshot/2023-04-24/05bcc4fadfc845a191d7b6a45fc930f7/8e3b8227-55ff-42a4-b68e-30266e665b6f.png)

这种方法使用了最大似然估计，用迭代的方法（$EM$）来求解这组参数。

由于$H$是一种一阶逻辑的表示形式，没办法和$\theta$一起优化，所以就把$H$当做和$z$一样的隐藏变量，统一用$\theta$去优化。所以有式2：

![img](https://static.cdn.readpaper.com/aiKnowledge/screenshot/2023-04-25/43fa466bf39e478cb8cd68fa64a99d00/2799931a-b0c2-4628-9e41-c7f7332e0895.png)

整个学习方法分为2步：

- Expectation：首先通过采样获得$H,\theta$的期望
- Maximisation：通过优化$\theta$的方式来使式2右边达到最大（最大似然估计）

### Probabilistic Abduction-Induction Reasoning

对于每一对$<x, y>$都有可能性$P$：

![img](https://static.cdn.readpaper.com/aiKnowledge/screenshot/2023-04-25/47b6ffaa93234841b839584e244c7ca7/67e4acd0-2bd6-4ffa-b153-f54edc6dd965.png)

推理方式主要分为4步：

- 归纳得到假说$H$
- 通过$H \cup B$还有$y$去产生可能的伪标签$z$
- 根据式3、4，对于每一个$(H, z)$评分
  - ![img](https://static.cdn.readpaper.com/aiKnowledge/screenshot/2023-04-25/c3bee3a99dbb4156aca7ed65c9e58bc0/f06aac87-fe1c-45eb-8139-80e4f103adb1.png)

- 返回得分最高的结果

形象化的推理过程如图：

![Figure 1: Example of MetaAbd’s abduction-induction learning. Given training examples, background knowledge of abducible primitives and probabilistic facts generated by a perceptual neural net, MetaAbd learns an abductive logic program H and abduces relational facts as constraints (implemented with the CLP(Z) predicate “#=”1) over the input images; it then uses them to efficiently prune the search space of the most probable pseudo-labels z (in grey blocks) for training the neural network.](https://pdf.cdn.readpaper.com/parsed/fetch_target/ead33b8d5691f335f8b40bc2a460577b_2_Figure_1_918222183.png)

## Result

从手写数字串中直接推断累加累乘达到了sota效果

